{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6a0452c-5681-4040-9447-d3ca450e9a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully created database engine.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "CLEAN_DIR = \"../data_clean\"\n",
    "DATA_FILE = \"taxi_zone_lookup.csv\"\n",
    "TABLE_NAME = \"taxi_trips\"\n",
    "\n",
    "# PostgreSQL Connection Details (Customize these!)\n",
    "DB_USER = \"postgres\"  # Your PostgreSQL username\n",
    "DB_PASS = \"etes1209111\" # !! Replace with your actual password !!\n",
    "# DB_HOST = \"localhost\"\n",
    "DB_HOST = \"127.0.0.1\" \n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"nyc_taxi\"\n",
    "\n",
    "# SQLAlchemy Connection String\n",
    "DATABASE_URL = f\"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "try:\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "    print(\"‚úÖ Successfully created database engine.\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå ERROR: Ensure psycopg2-binary is installed: pip install psycopg2-binary\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079353d5-b49b-4b9d-a6ac-5c38674b8a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: ../data_clean\\taxi_zone_lookup.csv\n",
      "Read 265 rows from taxi_zone_lookup.csv\n",
      "Loading data into staging table: raw_location_lookup\n",
      "‚úÖ Data successfully loaded into 'raw_location_lookup'.\n"
     ]
    }
   ],
   "source": [
    "# --- File Path ---\n",
    "file_path = os.path.join(CLEAN_DIR, DATA_FILE)\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"‚ùå ERROR: Clean data file not found at: {file_path}\")\n",
    "    exit()\n",
    "# --- 1. Read the CSV ---\n",
    "print(f\"Reading data from: {file_path}\")\n",
    "try:\n",
    "    # Read the CSV (assuming the column names are as seen in the image)\n",
    "    location_df = pd.read_csv(file_path)\n",
    "    print(f\"Read {len(location_df)} rows from {DATA_FILE}\")\n",
    "\n",
    "    # Standardize column names (make them all lowercase for PostgreSQL)\n",
    "    location_df.columns = [\n",
    "        'locationid', \n",
    "        'borough', \n",
    "        'zone', \n",
    "        'service_zone'\n",
    "    ]\n",
    "    \n",
    "    # --- 2. Load to Staging Table in PostgreSQL ---\n",
    "    staging_table_name = \"raw_location_lookup\"\n",
    "    print(f\"Loading data into staging table: {staging_table_name}\")\n",
    "    \n",
    "    # Use to_sql to directly push the DataFrame to PostgreSQL\n",
    "    location_df.to_sql(\n",
    "        name=staging_table_name, \n",
    "        con=engine, \n",
    "        if_exists='replace', # Replace the table if it exists\n",
    "        index=False,         # Don't save the Pandas index as a column\n",
    "        method='multi'       # Use this method for better performance with small tables\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Data successfully loaded into '{staging_table_name}'.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: File not found at {file_path}. Check CLEAN_DIR and DATA_FILE constants.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå An error occurred during load: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341d84c6-f98b-4109-91f0-dd55ac40d702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing SQL to create final dimension table: dim_location\n",
      "‚úÖ Dim_Location created with 265 rows.\n",
      "\n",
      "üéâ The Star Schema is now fully complete (Fact, Dim_Date, Dim_Weather, Dim_Location).\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Create the final Dim_Location table ---\n",
    "dim_location_table = \"dim_location\"\n",
    "\n",
    "sql_create_dim_location = f\"\"\"\n",
    "DROP TABLE IF EXISTS {dim_location_table};\n",
    "CREATE TABLE {dim_location_table} AS\n",
    "SELECT\n",
    "    locationid AS location_key,  -- Renaming the key for clarity\n",
    "    zone AS location_name,       -- Descriptive name for reports\n",
    "    borough,\n",
    "    service_zone                 -- Keeping this for potential future analysis\n",
    "FROM\n",
    "    raw_location_lookup;         -- Source is the staging table\n",
    "\n",
    "-- Set the primary key for optimal join performance in Power BI\n",
    "ALTER TABLE {dim_location_table} ADD PRIMARY KEY (location_key);\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    print(f\"Executing SQL to create final dimension table: {dim_location_table}\")\n",
    "    connection.execute(text(sql_create_dim_location))\n",
    "    connection.commit()\n",
    "    \n",
    "    # --- 4. Validation Check ---\n",
    "    validation_query = f\"SELECT COUNT(*) FROM {dim_location_table};\"\n",
    "    count = connection.execute(text(validation_query)).scalar()\n",
    "    print(f\"‚úÖ Dim_Location created with {count} rows.\")\n",
    "    \n",
    "print(\"\\nüéâ The Star Schema is now fully complete (Fact, Dim_Date, Dim_Weather, Dim_Location).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f106ea4-812e-4e7f-bd7d-fdc17f0c8f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
